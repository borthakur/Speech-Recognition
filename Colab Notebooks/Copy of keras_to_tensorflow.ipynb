{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of keras_to_tensorflow.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"cUE543L0lPmI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618917041848,"user_tz":-330,"elapsed":105077,"user":{"displayName":"Croam Speech","photoUrl":"","userId":"11800440030975940372"}},"outputId":"ee300aa6-4ff1-40ed-84df-6ad410b3eb8c"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5-7g1BKYywTv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618917044890,"user_tz":-330,"elapsed":1638,"user":{"displayName":"Croam Speech","photoUrl":"","userId":"11800440030975940372"}},"outputId":"93b4e061-8464-4209-b49c-e12da8afde78"},"source":["import os\n","os.chdir('drive/My Drive')\n","os.listdir()"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['depthwise_conv2d.py',\n"," 'Colab Notebooks',\n"," 'logs',\n"," 'Pickles',\n"," 'Zips',\n"," 'model.py',\n"," 'data_preprocess.py',\n"," 'utils.py',\n"," 'CRoam Model Training  Report.pdf',\n"," 'speaker_ver1_model.h5',\n"," 'speaker_ver1_model.pb',\n"," 'speaker_ver1a_model.h5',\n"," 'speaker_ver1b_model.h5',\n"," 'speaker_ver1a_model.pb',\n"," 'graph_def_for_reference.pb.ascii',\n"," 'speaker_ver1b_model.pb',\n"," 'new_mix_help_train_x.pickle',\n"," 'new_mix_help_train_y.pickle',\n"," 'total_bachao_x_new.pickle',\n"," 'total_bachao_y_new.pickle',\n"," 'Data',\n"," 'Bachao_Models',\n"," 'Help_Models']"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"SLb38TfgyCYt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618917047390,"user_tz":-330,"elapsed":1448,"user":{"displayName":"Croam Speech","photoUrl":"","userId":"11800440030975940372"}},"outputId":"b064e313-3db4-4788-8aaf-e86d07aa0b8c"},"source":["os.chdir('Bachao_Models')\n","os.listdir()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['HDF5', 'protobuf', 'newbachao.pb', 'graph_def_for_reference.pb.ascii']"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"vMEbcgVzLRve","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1618921207001,"user_tz":-330,"elapsed":84133,"user":{"displayName":"Croam Speech","photoUrl":"","userId":"11800440030975940372"}},"outputId":"827887f0-ca0d-433b-fd07-a2f4ac50370d"},"source":["!pip install tensorflow==1.15\n","# !pip install tensorflow==2.2.0"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==1.15\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n","\u001b[K     |████████████████████████████████| 412.3MB 32kB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.12.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.12.4)\n","Collecting tensorboard<1.16.0,>=1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 40.9MB/s \n","\u001b[?25hCollecting tensorflow-estimator==1.15.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n","\u001b[K     |████████████████████████████████| 512kB 46.5MB/s \n","\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.32.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.36.2)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.19.5)\n","Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n","Collecting keras-applications>=1.0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 4.9MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.12.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (54.2.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.4)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.10.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.1)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=f6e54c14e8c2ca1d6cb95ed1dd3ba3477e4a46708385046d18aa13d5ea911bb1\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","Installing collected packages: tensorboard, tensorflow-estimator, gast, keras-applications, tensorflow\n","  Found existing installation: tensorboard 2.4.1\n","    Uninstalling tensorboard-2.4.1:\n","      Successfully uninstalled tensorboard-2.4.1\n","  Found existing installation: tensorflow-estimator 2.4.0\n","    Uninstalling tensorflow-estimator-2.4.0:\n","      Successfully uninstalled tensorflow-estimator-2.4.0\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: tensorflow 2.4.1\n","    Uninstalling tensorflow-2.4.1:\n","      Successfully uninstalled tensorflow-2.4.1\n","Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["gast","tensorboard","tensorflow"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"864qTDtnLbYS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618917055204,"user_tz":-330,"elapsed":2808,"user":{"displayName":"Croam Speech","photoUrl":"","userId":"11800440030975940372"}},"outputId":"1dce3f19-f8e0-4fa2-f374-fd99bba4b041"},"source":["import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '4'\n","import tensorflow as tf\n","from tensorflow import keras\n","print(\"TensorFlow version: \", tf.__version__)\n","print(\"Keras version: \", keras.__version__)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["TensorFlow version:  2.4.1\n","Keras version:  2.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9Z_6PkApmsJ0","colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1618917060233,"user_tz":-330,"elapsed":2067,"user":{"displayName":"Croam Speech","photoUrl":"","userId":"11800440030975940372"}},"outputId":"0e5a4485-925e-4472-cb69-c7e164d12b72"},"source":["'''\n","This script converts a .h5 Keras model into a Tensorflow .pb file.\n","Attribution: This script was adapted from https://github.com/amir-abdi/keras_to_tensorflow\n","MIT License\n","Copyright (c) 2017 bitbionic\n","Permission is hereby granted, free of charge, to any person obtaining a copy\n","of this software and associated documentation files (the \"Software\"), to deal\n","in the Software without restriction, including without limitation the rights\n","to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n","copies of the Software, and to permit persons to whom the Software is\n","furnished to do so, subject to the following conditions:\n","The above copyright notice and this permission notice shall be included in all\n","copies or substantial portions of the Software.\n","THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n","IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n","FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n","AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n","LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n","OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n","SOFTWARE.\n","'''\n","\n","import os\n","import os.path as osp\n","import argparse\n","\n","import tensorflow as tf\n","\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras import backend as K\n","\n","def convertGraph( modelPath, outdir, numoutputs, prefix, name):\n","    '''\n","    Converts an HD5F file to a .pb file for use with Tensorflow.\n","    Args:\n","        modelPath (str): path to the .h5 file\n","           outdir (str): path to the output directory\n","       numoutputs (int):   \n","           prefix (str): the prefix of the output aliasing\n","             name (str):\n","    Returns:\n","        None\n","    '''\n","    \n","    #NOTE: If using Python > 3.2, this could be replaced with os.makedirs( name, exist_ok=True )\n","    if not os.path.isdir(outdir):\n","        os.mkdir(outdir)\n","\n","    K.set_learning_phase(0)\n","\n","    net_model = load_model(modelPath,compile=False)\n","\n","    # Alias the outputs in the model - this sometimes makes them easier to access in TF\n","    pred = [None]*numoutputs\n","    pred_node_names = [None]*numoutputs\n","    for i in range(numoutputs):\n","        pred_node_names[i] = prefix+str(i)\n","        pred[i] = tf.identity(net_model.output[i], name=pred_node_names[i])\n","    print('Output nodes names are: ', pred_node_names)\n","    sess = K.get_session()\n","    \n","    # Write the graph in human readable\n","    f = 'graph_def_for_reference.pb.ascii'\n","    tf.train.write_graph(sess.graph.as_graph_def(), outdir, f, as_text=True)\n","    print('Saved the graph definition in ascii format at: ', osp.join(outdir, f))\n","    \n","    # Write the graph in binary .pb file\n","    from tensorflow.python.framework import graph_util\n","    from tensorflow.python.framework import graph_io\n","    constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), pred_node_names)\n","    graph_io.write_graph(constant_graph, outdir, name, as_text=False)\n","    print('Saved the constant graph (ready for inference) at: ', osp.join(outdir, name))\n","\n","'''\n","if __name__ == '__main__':\n","\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--model','-m', dest='model', required=True, help='REQUIRED: The HDF5 Keras model you wish to convert to .pb')\n","    parser.add_argument('--numout','-n', type=int, dest='num_out', required=True, help='REQUIRED: The number of outputs in the model.')\n","    parser.add_argument('--outdir','-o', dest='outdir', required=False, default='./', help='The directory to place the output files - default(\"./\")')\n","    parser.add_argument('--prefix','-p', dest='prefix', required=False, default='k2tfout', help='The prefix for the output aliasing - default(\"k2tfout\")')\n","    parser.add_argument('--name', dest='name', required=False, default='output_graph.pb', help='The name of the resulting output graph - default(\"output_graph.pb\")')\n","    args = parser.parse_args()\n","\n","    convertGraph( args.model, args.outdir, args.num_out, args.prefix, args.name )\n","'''"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nif __name__ == \\'__main__\\':\\n\\n    parser = argparse.ArgumentParser()\\n    parser.add_argument(\\'--model\\',\\'-m\\', dest=\\'model\\', required=True, help=\\'REQUIRED: The HDF5 Keras model you wish to convert to .pb\\')\\n    parser.add_argument(\\'--numout\\',\\'-n\\', type=int, dest=\\'num_out\\', required=True, help=\\'REQUIRED: The number of outputs in the model.\\')\\n    parser.add_argument(\\'--outdir\\',\\'-o\\', dest=\\'outdir\\', required=False, default=\\'./\\', help=\\'The directory to place the output files - default(\"./\")\\')\\n    parser.add_argument(\\'--prefix\\',\\'-p\\', dest=\\'prefix\\', required=False, default=\\'k2tfout\\', help=\\'The prefix for the output aliasing - default(\"k2tfout\")\\')\\n    parser.add_argument(\\'--name\\', dest=\\'name\\', required=False, default=\\'output_graph.pb\\', help=\\'The name of the resulting output graph - default(\"output_graph.pb\")\\')\\n    args = parser.parse_args()\\n\\n    convertGraph( args.model, args.outdir, args.num_out, args.prefix, args.name )\\n'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"IAdWwRv3lH-J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618917063965,"user_tz":-330,"elapsed":1428,"user":{"displayName":"Croam Speech","photoUrl":"","userId":"11800440030975940372"}},"outputId":"9253c3f0-8fb1-4536-8cfa-688df300d5a5"},"source":["os.listdir()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['HDF5', 'protobuf', 'newbachao.pb', 'graph_def_for_reference.pb.ascii']"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"id":"YBvAbybEzkY0","executionInfo":{"status":"error","timestamp":1618921079818,"user_tz":-330,"elapsed":1850,"user":{"displayName":"Croam Speech","photoUrl":"","userId":"11800440030975940372"}},"outputId":"2a89050c-2cf1-4e52-d319-8494be7a36fd"},"source":["modelPath = 'HDF5/serverbachao1.h5'\n","net_model = load_model(modelPath,compile=False)\n","net_model.summary()"],"execution_count":8,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-b6975658af9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodelPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'HDF5/serverbachao1.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnet_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelPath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    112\u001b[0m                   (export_dir,\n\u001b[1;32m    113\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: HDF5/serverbachao1.h5/{saved_model.pbtxt|saved_model.pb}"]}]},{"cell_type":"code","metadata":{"id":"L6bNuB-xdctP"},"source":["import tensorflow.python.keras.backend as K\n","import tensorflow.compat.v1 as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fvnvbDecB_u_","colab":{"base_uri":"https://localhost:8080/","height":525},"executionInfo":{"status":"error","timestamp":1617885083344,"user_tz":-330,"elapsed":2372,"user":{"displayName":"Croam Speech","photoUrl":"","userId":"11800440030975940372"}},"outputId":"495ecad2-f646-4e58-d37c-f5b121f30097"},"source":["outdir = './'\n","numoutputs = 1\n","prefix = 'output'\n","name = 'serverbachao1.pb'\n","convertGraph(modelPath, outdir, numoutputs, prefix, name)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Output nodes names are:  ['output0']\n","Saved the graph definition in ascii format at:  ./graph_def_for_reference.pb.ascii\n","WARNING:tensorflow:From <ipython-input-4-07ea4ab7ea84>:70: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/convert_to_constants.py:856: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n"],"name":"stdout"},{"output_type":"error","ename":"AssertionError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-7648460428f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'output'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'serverbachao1.pb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mconvertGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumoutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-4-07ea4ab7ea84>\u001b[0m in \u001b[0;36mconvertGraph\u001b[0;34m(modelPath, outdir, numoutputs, prefix, name)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph_io\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mconstant_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_variables_to_constants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_node_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mgraph_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstant_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saved the constant graph (ready for inference) at: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m               instructions)\n\u001b[0;32m--> 340\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_deprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/graph_util_impl.py\u001b[0m in \u001b[0;36mconvert_variables_to_constants\u001b[0;34m(sess, input_graph_def, output_node_names, variable_names_whitelist, variable_names_blacklist)\u001b[0m\n\u001b[1;32m    278\u001b[0m       \u001b[0moutput_node_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_node_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0mvariable_names_allowlist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariable_names_whitelist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m       variable_names_denylist=variable_names_blacklist)\n\u001b[0m\u001b[1;32m    281\u001b[0m   \u001b[0;31m# The previous code logic generated an empty versions field, we clear it here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m   \u001b[0;31m# to maintain backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/convert_to_constants.py\u001b[0m in \u001b[0;36mconvert_variables_to_constants_from_session_graph\u001b[0;34m(session, graph_def, output_node_names, variable_names_allowlist, variable_names_denylist)\u001b[0m\n\u001b[1;32m   1146\u001b[0m           \u001b[0moutput_node_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_node_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m           \u001b[0mvariable_names_allowlist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariable_names_allowlist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m           variable_names_denylist=variable_names_denylist))\n\u001b[0m\u001b[1;32m   1149\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/convert_to_constants.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session, graph_def, output_node_names, variable_names_allowlist, variable_names_denylist)\u001b[0m\n\u001b[1;32m    854\u001b[0m                \u001b[0mvariable_names_allowlist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                variable_names_denylist=None):\n\u001b[0;32m--> 856\u001b[0;31m     \u001b[0mgraph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_sub_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_node_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m     super(_SessionConverterData, self).__init__(\n\u001b[1;32m    858\u001b[0m         \u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m               instructions)\n\u001b[0;32m--> 340\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_deprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/graph_util_impl.py\u001b[0m in \u001b[0;36mextract_sub_graph\u001b[0;34m(graph_def, dest_nodes)\u001b[0m\n\u001b[1;32m    206\u001b[0m   name_to_input_name, name_to_node, name_to_seq_num = _extract_graph_summary(\n\u001b[1;32m    207\u001b[0m       graph_def)\n\u001b[0;32m--> 208\u001b[0;31m   \u001b[0m_assert_nodes_are_present\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_to_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m   \u001b[0mnodes_to_keep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_bfs_for_reachable_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_to_input_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/graph_util_impl.py\u001b[0m in \u001b[0;36m_assert_nodes_are_present\u001b[0;34m(name_to_node, nodes)\u001b[0m\n\u001b[1;32m    161\u001b[0m   \u001b[0;34m\"\"\"Assert that nodes are present in the graph.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname_to_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%s is not in graph\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: output0 is not in graph"]}]},{"cell_type":"code","metadata":{"id":"TxzQP7hAUBub","colab":{"base_uri":"https://localhost:8080/","height":229},"executionInfo":{"status":"error","timestamp":1618921110484,"user_tz":-330,"elapsed":1483,"user":{"displayName":"Croam Speech","photoUrl":"","userId":"11800440030975940372"}},"outputId":"12bf0a23-a323-4965-caf9-eee5f51d964c"},"source":["import tensorflow as tf\n","from tensorflow.python.platform import gfile\n","GRAPH_PB_PATH = 'help1.pb'\n","with tf.Session() as sess:\n","   print(\"loading graph....\")\n","   with gfile.FastGFile(GRAPH_PB_PATH,'rb') as f:\n","       graph_def = tf.GraphDef()\n","   graph_def.ParseFromString(f.read())\n","   sess.graph.as_default()\n","   tf.import_graph_def(graph_def, name='')\n","   graph_nodes=[n for n in graph_def.node]\n","   names = []\n","   for t in graph_nodes:\n","      names.append(t.name)\n","   print(names)"],"execution_count":9,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-ebbccca169cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mGRAPH_PB_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'serverbachao1.pb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading graph....\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m    \u001b[0;32mwith\u001b[0m \u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFastGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGRAPH_PB_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"]}]},{"cell_type":"code","metadata":{"id":"MkgxzlnV8IYC","colab":{"base_uri":"https://localhost:8080/","height":555},"executionInfo":{"status":"error","timestamp":1617882163193,"user_tz":-330,"elapsed":1762,"user":{"displayName":"Croam Speech","photoUrl":"","userId":"11800440030975940372"}},"outputId":"f0d976fa-9be2-47f3-b128-eabb6eb369c2"},"source":["from keras.utils.vis_utils import plot_model\n","plot_model(net_model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.layers.experimental.preprocessing'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-e21e8acbbaf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvis_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model_plot.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     raise ImportError(\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;34m'Keras requires TensorFlow 2.2 or higher. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         'Install TensorFlow via `pip install tensorflow`')\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"rGhTrql28f-i"},"source":["[n.name for n in tf.get_default_graph().as_graph_def().node][0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg3eX6av8pvz"},"source":["tf.get_default_graph()"],"execution_count":null,"outputs":[]}]}